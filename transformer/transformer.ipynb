{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from livelossplot import PlotLossesKeras\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train windows: (1559382, 10, 17)\n",
      "Test windows: (307815, 10, 17)\n",
      "Ratio = 0.16485405664212185\n"
     ]
    }
   ],
   "source": [
    "paths = list(glob(\"../outputs/withNewFeatures/dataByLocation*.csv\"))\n",
    "debug_limit = None\n",
    "if debug_limit == None:\n",
    "    debug_limit = len(paths)\n",
    "elif debug_limit < 2:\n",
    "    print(\"Insufficient number of files to debug. Setting debug_limit to 2.\")\n",
    "    debug_limit = 2\n",
    "test_train_ratio = 0.2\n",
    "window_length = 10\n",
    "min_drive_length = 5 * 60\n",
    "\n",
    "all_windows = []\n",
    "train_windows = []\n",
    "test_windows = []\n",
    "for i,path in enumerate(paths[:debug_limit]):\n",
    "    df = pd.read_csv(path).dropna().drop_duplicates()\n",
    "    a = df.to_numpy()\n",
    "    if a[-1][0] - a[0][0] < min_drive_length:\n",
    "        # print(f'Skipping {path.split(\"/\")[-1]} because it is too short')\n",
    "        continue\n",
    "    df = df.drop(columns=[\"Time\"])\n",
    "    a = df.to_numpy()\n",
    "    windows = np.lib.stride_tricks.sliding_window_view(a, (window_length, a.shape[1]))\n",
    "    windows = list(np.reshape(windows, (windows.shape[0], window_length, a.shape[1])))\n",
    "    all_windows += windows\n",
    "    isTest = i % int(1/test_train_ratio) == 0\n",
    "    if isTest:\n",
    "        test_windows += windows\n",
    "    else:\n",
    "        train_windows += windows\n",
    "\n",
    "all_windows = np.array(all_windows)\n",
    "train_windows = np.array(train_windows)\n",
    "test_windows = np.array(test_windows)\n",
    "\n",
    "for subset in [train_windows, test_windows]:\n",
    "    X = np.zeros((subset.shape[0], window_length, subset.shape[2] - 2))\n",
    "    y = np.zeros((subset.shape[0], 2))\n",
    "    for i,window in enumerate(subset):\n",
    "        X[i] = window[:, 2:]\n",
    "        y[i] = [window[0, 0] - window[-1, 0], window[0, 1] - window[-1, 1]]\n",
    "    if subset is train_windows:\n",
    "        X_train = X\n",
    "        y_train = y\n",
    "    elif subset is test_windows:\n",
    "        X_test = X\n",
    "        y_test = y\n",
    "\n",
    "print(\"Train windows:\", X_train.shape)\n",
    "print(\"Test windows:\", X_test.shape)\n",
    "print(\"Ratio =\", X_test.shape[0] / (X_train.shape[0] + X_test.shape[0]))\n",
    "\n",
    "def column_from_windows(windows, i):\n",
    "    column = windows[:, :, i]\n",
    "    column = np.reshape(column, (column.shape[0] * column.shape[1],))\n",
    "    column_without_dupes = np.array([value for i,value in enumerate(column) if i < window_length or i % window_length == window_length - 1])\n",
    "    return column_without_dupes\n",
    "\n",
    "def scaler_for_windows(windows):\n",
    "    realigned = np.transpose(np.array([column_from_windows(windows, i) for i in range(windows.shape[2])]))\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(realigned)\n",
    "    with open(\"window_scaler.pkl\", \"wb\") as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    return scaler\n",
    "\n",
    "def scaler_for_labels(labels):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(labels)\n",
    "    with open(\"label_scaler.pkl\", \"wb\") as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    return scaler\n",
    "\n",
    "def scale_windows(windows, scaler):\n",
    "    new_windows = np.zeros(windows.shape)\n",
    "    for i,window in enumerate(windows):\n",
    "        new_windows[i] = scaler.transform(window)\n",
    "    return new_windows\n",
    "\n",
    "def scale_labels(labels, scaler):\n",
    "    new_labels = scaler.transform(labels)\n",
    "    return new_labels\n",
    "\n",
    "def unwindow(windows):\n",
    "    realigned = np.transpose(np.array([column_from_windows(windows, i) for i in range(windows.shape[2])]))\n",
    "    return realigned\n",
    "\n",
    "window_scaler = scaler_for_windows(X_train)\n",
    "label_scaler = scaler_for_labels(y_train)\n",
    "\n",
    "X_train = scale_windows(X_train, window_scaler)\n",
    "y_train = scale_labels(y_train, label_scaler)\n",
    "X_test = scale_windows(X_test, window_scaler)\n",
    "y_test = scale_labels(y_test, label_scaler)\n",
    "\n",
    "X_train = unwindow(X_train)\n",
    "X_test = unwindow(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "train_data = keras.utils.timeseries_dataset_from_array(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    window_length,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "test_data = keras.utils.timeseries_dataset_from_array(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    window_length,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(y_train.shape[1], activation=\"linear\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 22:51:31.563719: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  67/3046 [..............................] - ETA: 18:16 - loss: 0.1315 - root_mean_squared_error: 0.3626 - RMSE_1: 0.3363 - RMSE_2: 0.2846"
     ]
    }
   ],
   "source": [
    "input_shape = (window_length, X_train.shape[-1])\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "def inner_part_custom_metric(y_true, y_pred, i):\n",
    "    d = y_pred-y_true\n",
    "    root_square_d = tf.math.sqrt(tf.math.square(d))\n",
    "    return root_square_d[:,i]\n",
    "\n",
    "def custom_metric_output_1():\n",
    "    def RMSE_1(y_true, y_pred):\n",
    "        return inner_part_custom_metric(y_true, y_pred, 0)\n",
    "    return RMSE_1\n",
    "\n",
    "def custom_metric_output_2():\n",
    "    def RMSE_2(y_true, y_pred):\n",
    "        return inner_part_custom_metric(y_true, y_pred, 1)\n",
    "    return RMSE_2\n",
    "\n",
    "model.compile(\n",
    "    loss=\"mean_squared_error\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[keras.metrics.RootMeanSquaredError(),custom_metric_output_1(), custom_metric_output_2()],\n",
    ")\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    \"checkpoints\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    save_freq=\"epoch\"\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True), PlotLossesKeras()]\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=test_data,\n",
    "    validation_steps=100,\n",
    "    epochs=200,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9df139cf4fd7fbfed7596b00795d916641fdf384a73a205999ad45fcffc5436"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
