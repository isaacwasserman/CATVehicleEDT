{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d205aa4-59b3-4733-9214-4c3d252be5ef",
   "metadata": {},
   "source": [
    "# CNN (new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b7838a-a5da-4744-b17a-cd51fc95259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, regularizers,Model, utils\n",
    "from tensorflow.keras.callbacks import TensorBoard,EarlyStopping\n",
    "%load_ext tensorboard\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import widgets\n",
    "\n",
    "from datetime import datetime,time\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e08c4-ef66-4fef-ac74-96334592b9ef",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c36efa-093a-4820-8caf-8d649892680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('otherLargeFiles/CNN-dataset.pkl', 'rb')     \n",
    "dataset = pickle.load(dbfile)\n",
    "dbfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c2ee51-5eab-4e63-8695-8702a4016fc9",
   "metadata": {},
   "source": [
    "## Split into training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ebb194-513f-4d63-a075-5ba021258e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitudeLabels = dataset[\"labels\"][:,0]\n",
    "latitudeLabels = dataset[\"labels\"][:,1]\n",
    "\n",
    "combinedLabels = np.concatenate((np.reshape(longitudeLabels, (-1,1)), np.reshape(latitudeLabels, (-1,1))), axis=1)\n",
    "trainInputs, testInputs, trainLabels, testLabels = train_test_split(dataset[\"samples\"], combinedLabels, test_size=0.5, shuffle=False)\n",
    "trainInputs, valInputs, trainLabels, valLabels = train_test_split(trainInputs, trainLabels, test_size=0.15, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d57020f-c0ae-4362-b176-5b2f58ac3762",
   "metadata": {},
   "source": [
    "## Construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd623a-1505-45d5-89fa-52fed76b5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify input dimensionality\n",
    "outputDimension = 2\n",
    "sequenceLength = trainInputs.shape[1]\n",
    "\n",
    "#construct our neural network\n",
    "convActivation = \"relu\"\n",
    "kernelSize = 9\n",
    "batchSize = 64\n",
    "epochs = 10\n",
    "\n",
    "def convolutionalLayer(size, name):\n",
    "    return layers.Conv1DTranspose(size, kernel_size=kernelSize, activation=convActivation, name=name, kernel_regularizer=regularizers.l2(1e-5), padding=\"same\")\n",
    "\n",
    "inputLayer = layers.Input(shape=(sequenceLength, 13), name=\"input\")\n",
    "modelLayers = [inputLayer]\n",
    "\n",
    "def layerByName(n):\n",
    "    for layer in modelLayers:\n",
    "        if layer.name.split(\"/\")[0] == n:\n",
    "            return layer\n",
    "    return None\n",
    "\n",
    "\n",
    "modelLayers.append(convolutionalLayer(16,\"conv0\")(modelLayers[-1]))\n",
    "modelLayers.append(convolutionalLayer(8,\"conv1\")(modelLayers[-1]))\n",
    "modelLayers.append(convolutionalLayer(4,\"conv2\")(modelLayers[-1]))\n",
    "modelLayers.append(convolutionalLayer(2,\"conv3\")(modelLayers[-1]))\n",
    "modelLayers.append(convolutionalLayer(2,\"conv4\")(modelLayers[-1]))\n",
    "modelLayers.append(layers.Concatenate(name=\"concat0\")([layerByName(\"conv4\"), layerByName(\"conv3\")]))\n",
    "modelLayers.append(convolutionalLayer(4,\"conv5\")(modelLayers[-1]))\n",
    "modelLayers.append(layers.Concatenate(name=\"concat1\")([layerByName(\"conv5\"), layerByName(\"conv2\")]))\n",
    "modelLayers.append(convolutionalLayer(8,\"conv6\")(modelLayers[-1]))\n",
    "modelLayers.append(layers.Concatenate(name=\"concat2\")([layerByName(\"conv6\"), layerByName(\"conv1\")]))\n",
    "modelLayers.append(convolutionalLayer(16,\"conv7\")(modelLayers[-1]))\n",
    "modelLayers.append(layers.Concatenate(name=\"concat3\")([layerByName(\"conv7\"), layerByName(\"conv0\")]))\n",
    "modelLayers.append(layers.Dense(32, activation='sigmoid', name=\"dense1\", kernel_regularizer=regularizers.l2(1e-5))(modelLayers[-1]))\n",
    "modelLayers.append(layers.Flatten(name=\"flatten1\")(modelLayers[-1]))\n",
    "outputLayer = layers.Dense(outputDimension, activation='sigmoid', name=\"output\")(modelLayers[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4e615f-79ef-4597-b161-6cca6d3e5753",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a3c90c-5814-4401-af8e-7d60efa2332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedModel = Model(inputs=inputLayer, outputs=[outputLayer], name='combined_mlp')\n",
    "combinedModel.compile(loss='mean_squared_error', metrics=[tf.keras.metrics.RootMeanSquaredError()], optimizer='adam')\n",
    "combinedModel.save('model.h5')\n",
    "combinedModel.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc56a264-1737-439d-ae8d-b163368ff081",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c72825-8efe-47b2-8ff9-76149d11372c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "combinedHistory = combinedModel.fit(trainInputs, trainLabels, epochs=epochs, batch_size=batchSize, callbacks=[PlotLossesKeras(),tensorboard_callback], validation_data=(valInputs, valLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac86e087-912b-48d9-ba96-a94dc52849cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"min_val_loss\": [],\n",
    "    \"hidden_layer_sizes\": [],\n",
    "    \"activation\": [],\n",
    "    \"kernel_size\": [],\n",
    "    \"batch_size\": [],\n",
    "    \"epochs\": []\n",
    "}).to_csv(\"trainingLogs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dde37d-6bb5-45fa-bd95-249310640068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainingLogItem = {\n",
    "    \"min_val_loss\": min(combinedHistory.history[\"val_loss\"]),\n",
    "    \"hidden_layer_sizes\": hiddenLayerSizes,\n",
    "    \"activation\": convActivation,\n",
    "    \"kernel_size\": kernelSize,\n",
    "    \"batch_size\": batchSize,\n",
    "    \"epochs\": epochs\n",
    "}\n",
    "\n",
    "trainingLogs = pd.read_csv(\"trainingLogs.csv\")\n",
    "trainingLogs.append(trainingLogItem, ignore_index=True)\n",
    "trainingLogs.to_csv(\"trainingLogs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e304e5-b10f-453f-b8d3-86aad2e0362c",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6611810-b46e-4629-9747-0f70a3b8f86e",
   "metadata": {},
   "source": [
    "### Predict Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d7e29a-00e6-4a9f-b61d-2f80acdae0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = combinedModel.predict(testInputs)\n",
    "\n",
    "scatterData = pd.DataFrame({\n",
    "    \"index\":np.arange(predictions[:,0].shape[0]),\n",
    "    \"long_predicted\": predictions[:,0].reshape(predictions[:,0].shape[0]),\n",
    "    \"long_actual\": testLabels[:,0].reshape(testLabels[:,0].shape[0]),\n",
    "    \"lat_predicted\": predictions[:,1].reshape(predictions[:,1].shape[0]),\n",
    "    \"lat_actual\": testLabels[:,1].reshape(testLabels[:,1].shape[0])\n",
    "})\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_predicted, name=\"long_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_actual, name=\"long_actual\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_predicted, name=\"lat_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_actual, name=\"lat_actual\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5df780-5df8-4a5c-9504-c7a7676731fc",
   "metadata": {},
   "source": [
    "### Predict Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7de4e4-3bbf-4ec1-845f-dbe30ade444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = combinedModel.predict(trainInputs)\n",
    "\n",
    "scatterData = pd.DataFrame({\n",
    "    \"index\":np.arange(predictions[:,0].shape[0]),\n",
    "    \"long_predicted\": predictions[:,0].reshape(predictions[:,0].shape[0]),\n",
    "    \"long_actual\": trainLabels[:,0].reshape(trainLabels[:,0].shape[0]),\n",
    "    \"lat_predicted\": predictions[:,1].reshape(predictions[:,1].shape[0]),\n",
    "    \"lat_actual\": trainLabels[:,1].reshape(trainLabels[:,1].shape[0])\n",
    "})\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_predicted, name=\"long_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_actual, name=\"long_actual\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_predicted, name=\"lat_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_actual, name=\"lat_actual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa84159-7f1c-48c9-9059-afb2093db787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f6215-43ec-42e3-bbf1-be6af04dea30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
