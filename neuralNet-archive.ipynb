{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb22349-8301-4ddd-8029-e0408ce53e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets\n",
    "from sklearn import preprocessing\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, regularizers,Model, utils\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from datetime import time\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "from livelossplot import PlotLossesKeras\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b95384-e38a-4593-98b9-7645c5fae293",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivePaths = [\"outputs/dataByLocation_2020-11-21-16-00-26_5FNYF6H05HB089022.csv\"]\n",
    "drivePaths = [str(path) for path in Path(\".\").rglob(\"outputs/dataByLocation*.csv\")][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf2d374-8b73-4803-8b12-4423bf3ed255",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsamplingPeriod = 1\n",
    "\n",
    "drivesWithLocation = []\n",
    "drivesWithoutLocation = []\n",
    "for drivePath in drivePaths:\n",
    "    drive = pd.read_csv(drivePath)\n",
    "    drive = drive.iloc[::subsamplingPeriod]\n",
    "    driveWithoutLocation = drive.drop(columns=[\"Time\", \"Longitude\", \"Latitude\"])\n",
    "    drivesWithLocation.append(drive)\n",
    "    drivesWithoutLocation.append(driveWithoutLocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd93df7-465f-4969-8cca-03d54fb0def2",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d319d2b-ca5f-45f5-bb9a-3e5cff8b745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedDrives = []\n",
    "for drive in drivesWithoutLocation:\n",
    "    drive = drive.values[:]\n",
    "    standard_scaler = preprocessing.StandardScaler()\n",
    "    data_normalized = standard_scaler.fit_transform(drive)\n",
    "    data_normalized = pd.DataFrame(data_normalized)\n",
    "    normalizedDrives.append(data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5df908d-72e8-4507-b130-b2ec3d4cd9a7",
   "metadata": {},
   "source": [
    "## Window Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ea798a-56ff-481b-a90d-30a793d7f5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenceLength = 50\n",
    "features = ['Speed',\n",
    "            'LatAcceleration',\n",
    "            'LongAcceleration',\n",
    "            'SteerTorque',\n",
    "            'SteerRate',\n",
    "            'SteerAngle',\n",
    "            'FLWheelSpeed',\n",
    "            'FRWheelSpeed',\n",
    "            'RRWheelSpeed',\n",
    "            'RLWheelSpeed']\n",
    "\n",
    "windowedDrives = []\n",
    "for drive in normalizedDrives:\n",
    "    data_df = drive\n",
    "    stackedData = []\n",
    "    # split can_data into subsampled sequences\n",
    "    for i in range(len(data_df)-sequenceLength):\n",
    "        stackedData.append(data_df[i:i+sequenceLength])\n",
    "    stackedData = np.array(stackedData)\n",
    "    windowedDrives.append(stackedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb3ebd-8bd2-444c-b11c-8fdfcb6840a2",
   "metadata": {},
   "source": [
    "## Generate Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591e8b3-1cbc-4837-b3ee-4d0175fed431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = {\"samples\":[], \"labels\":[]}\n",
    "for k,drive in enumerate(windowedDrives):\n",
    "    for i,window in enumerate(drive[:-1]):\n",
    "        last = drivesWithLocation[k].iloc[i]\n",
    "        lastLong = last.Longitude\n",
    "        lastLat = last.Latitude\n",
    "        cur = drivesWithLocation[k].iloc[i+5]\n",
    "        curLong = cur.Longitude\n",
    "        curLat = cur.Latitude\n",
    "        \n",
    "        dataset[\"samples\"].append(window)\n",
    "        dataset[\"labels\"].append([curLong - lastLong, curLat - lastLat])\n",
    "dataset = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61849443-9587-4545-8a4d-ddda7ef052ab",
   "metadata": {},
   "source": [
    "### Normalize labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a9e7a7-f589-4c7d-b8b5-6ac43f07a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "originalLabels = dataset[\"labels\"].tolist()\n",
    "# originalLabels = np.array(originalLabels)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "labels_normalized = scaler.fit_transform(originalLabels)\n",
    "\n",
    "dataset[\"labels\"] = labels_normalized\n",
    "labels_normalized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cae1246-b0ba-4f91-b14b-da7b66b96c5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Formalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63dd48d-b632-4f5e-9bad-813f6b5adc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples = np.stack(dataset[\"samples\"])\n",
    "labels = labels_normalized\n",
    "dataset = {\"samples\": samples, \"labels\": labels}\n",
    "\n",
    "longitudeLabels = dataset[\"labels\"][:,0]\n",
    "latitudeLabels = dataset[\"labels\"][:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7ce396-6de3-423b-b4e9-9dc7d4e5c64f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef6067e-065a-489a-bccf-41b93b548e2c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3baf5c-797c-458b-ad62-46a99d8e48b6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Split into training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538bfa1a-82d4-4cd1-a68a-795f01b74f91",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "longTrainInputs, longValInputs, longTrainLabels, longValLabels = train_test_split(dataset[\"samples\"], longitudeLabels, test_size=0.5, shuffle=False)\n",
    "latTrainInputs, latValInputs, latTrainLabels, latValLabels = train_test_split(dataset[\"samples\"], latitudeLabels, test_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647accc0-4e20-4e4b-bdd9-a179907444f6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e27ab-8c06-4d74-a470-433376306098",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#specify input dimensionality\n",
    "inputDimension = samples[0].shape[0]*samples[0].shape[1]\n",
    "outputDimension = 1\n",
    "\n",
    "#construct our neural network\n",
    "hiddenLayerSizes = [32,128, 512, 512, 128]\n",
    "\n",
    "#set up our input layer\n",
    "inputLayer = layers.Input(shape=(sequenceLength, 13))\n",
    "\n",
    "#set up our hidden layers\n",
    "curLayer = 0\n",
    "previousLayer = inputLayer\n",
    "for i,curLayerSize in enumerate(hiddenLayerSizes):\n",
    "    previousLayer = layers.Dense(curLayerSize,\n",
    "                                 activation='linear', \n",
    "                                 name=str(curLayerSize)+'_hiddenLayer'+str(i)\n",
    "                                )(previousLayer)\n",
    "    previousLayer = layers.LeakyReLU(alpha=0.3)(previousLayer)\n",
    "    previousLayer = layers.Dropout(\n",
    "                                    rate=0.5\n",
    "                                    )(previousLayer)\n",
    "previousLayer = layers.Flatten()(previousLayer)\n",
    "    \n",
    "outputLayer = layers.Dense(outputDimension, activation='sigmoid')(previousLayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e2808-3757-4a16-a0ba-ec3f33d96d08",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdbb2ae-5a3d-4a42-8384-f1962aad14a3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#compile separate models\n",
    "longModel = Model(inputs=inputLayer, outputs=[outputLayer], name='longitude_mlp')\n",
    "latModel = Model(inputs=inputLayer, outputs=[outputLayer], name='latitude_mlp')\n",
    "longModel.compile(loss='mean_squared_error', metrics=[tf.keras.metrics.RootMeanSquaredError()], optimizer='adam')\n",
    "latModel.compile(loss='mean_squared_error', metrics=[tf.keras.metrics.RootMeanSquaredError()], optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd102a65-6aef-49a4-88f3-807d057f65eb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667064a9-db30-4f77-b340-002a2f87822a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train the mlp\n",
    "longHistory = longModel.fit(longTrainInputs, longTrainLabels, epochs=3, batch_size=64, callbacks=[PlotLossesKeras()], validation_data=(longValInputs, longValLabels))\n",
    "latHistory = latModel.fit(latTrainInputs, latTrainLabels, epochs=3, batch_size=64, callbacks=[PlotLossesKeras()], validation_data=(latValInputs, latValLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90844967-6b50-4a50-b177-9751838bce31",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb1441-a654-4add-bfaa-7db77d66fe8b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "##### Predict Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab4af1-c74e-4255-9356-1a30d2c1ce23",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "longPredictions = longModel.predict(longValInputs)\n",
    "latPredictions = latModel.predict(latValInputs)\n",
    "\n",
    "scatterData = pd.DataFrame({\n",
    "    \"index\":np.arange(longPredictions.shape[0]),\n",
    "    \"long_predicted\": longPredictions.reshape(longPredictions.shape[0]),\n",
    "    \"long_actual\": longValLabels.reshape(longValLabels.shape[0]),\n",
    "    \"lat_predicted\": latPredictions.reshape(latPredictions.shape[0]),\n",
    "    \"lat_actual\": latValLabels.reshape(latValLabels.shape[0])\n",
    "})\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_predicted, name=\"long_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_actual, name=\"long_actual\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_predicted, name=\"lat_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_actual, name=\"lat_actual\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafe3be8-69d1-4c18-b21f-0c8331bbd631",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "##### Predict Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d11f56-6138-48e6-97b5-f67472f243db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "longPredictions = longModel.predict(longTrainInputs)\n",
    "latPredictions = latModel.predict(latTrainInputs)\n",
    "\n",
    "scatterData = pd.DataFrame({\n",
    "    \"index\":np.arange(longPredictions.shape[0]),\n",
    "    \"long_predicted\": longPredictions.reshape(longPredictions.shape[0]),\n",
    "    \"long_actual\": longTrainLabels.reshape(longTrainLabels.shape[0]),\n",
    "    \"lat_predicted\": latPredictions.reshape(latPredictions.shape[0]),\n",
    "    \"lat_actual\": latTrainLabels.reshape(latTrainLabels.shape[0])\n",
    "})\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_predicted, name=\"long_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_actual, name=\"long_actual\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_predicted, name=\"lat_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_actual, name=\"lat_actual\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc3188-b110-40ab-be20-349ce71d91cf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### MLP (combined lat + long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6307d29d-7fa8-4220-9278-4eade3ea5aa9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Split into training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264b558f-d4f0-424c-9d3e-f48784137aa2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combinedLabels = np.concatenate((np.reshape(longitudeLabels, (-1,1)), np.reshape(latitudeLabels, (-1,1))), axis=1)\n",
    "trainInputs, valInputs, trainLabels, valLabels = train_test_split(dataset[\"samples\"], combinedLabels, test_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4be72c-77cd-4591-83b9-a6be81eeca0e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfa4b05-8762-4f20-8fe4-6b6b792946c2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#specify input dimensionality\n",
    "inputDimension = samples[0].shape[0]*samples[0].shape[1]\n",
    "outputDimension = 2\n",
    "\n",
    "#construct our neural network\n",
    "hiddenLayerSizes = [32]\n",
    "\n",
    "#set up our input layer\n",
    "inputLayer = layers.Input(shape=(sequenceLength, 13))\n",
    "\n",
    "#set up our hidden layers\n",
    "curLayer = 0\n",
    "previousLayer = inputLayer\n",
    "for i,curLayerSize in enumerate(hiddenLayerSizes):\n",
    "    previousLayer = layers.Dense(curLayerSize,\n",
    "                                 activation='linear', \n",
    "                                 name=str(curLayerSize)+'_hiddenLayer'+str(i)\n",
    "                                )(previousLayer)\n",
    "    previousLayer = layers.LeakyReLU(alpha=0.3)(previousLayer)\n",
    "    previousLayer = layers.Dropout(\n",
    "                                    rate=0.5\n",
    "                                    )(previousLayer)\n",
    "previousLayer = layers.Flatten()(previousLayer)\n",
    "    \n",
    "outputLayer = layers.Dense(outputDimension, activation='sigmoid')(previousLayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46c1f9-ad61-463c-87fc-3a25fbdb5d4e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80389d30-90d8-482b-afee-85a0fbaeabde",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#compile separate models\n",
    "combinedModel = Model(inputs=inputLayer, outputs=[outputLayer], name='combined_mlp')\n",
    "combinedModel.compile(loss='mean_squared_error', metrics=[tf.keras.metrics.RootMeanSquaredError()], optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0771c35-48a6-4910-827a-18a0b2bb63bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab0eb9-a60e-4267-ad9e-ec8a4e0de258",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train the mlp\n",
    "combinedHistory = combinedModel.fit(trainInputs, trainLabels, epochs=25, batch_size=32, callbacks=[PlotLossesKeras()], validation_data=(valInputs, valLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1fd3c-476b-4dfc-84a4-6862d16ce996",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb2d553-c430-4098-9862-af8502dd8668",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "##### Predict Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593393ea-d2d4-41ab-8f1d-20c3284a6875",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = combinedModel.predict(valInputs)\n",
    "\n",
    "scatterData = pd.DataFrame({\n",
    "    \"index\":np.arange(predictions[:,0].shape[0]),\n",
    "    \"long_predicted\": predictions[:,0].reshape(predictions[:,0].shape[0]),\n",
    "    \"long_actual\": valLabels[:,0].reshape(valLabels[:,0].shape[0]),\n",
    "    \"lat_predicted\": predictions[:,1].reshape(predictions[:,1].shape[0]),\n",
    "    \"lat_actual\": valLabels[:,1].reshape(valLabels[:,1].shape[0])\n",
    "})\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_predicted, name=\"long_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_actual, name=\"long_actual\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_predicted, name=\"lat_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_actual, name=\"lat_actual\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234d9e7d-bdd3-4959-bee4-cae25ace46b1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "##### Predict Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2906e8-e2bb-4c5f-a583-627eaaed837e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = combinedModel.predict(trainInputs)\n",
    "\n",
    "scatterData = pd.DataFrame({\n",
    "    \"index\":np.arange(predictions[:,0].shape[0]),\n",
    "    \"long_predicted\": predictions[:,0].reshape(predictions[:,0].shape[0]),\n",
    "    \"long_actual\": trainLabels[:,0].reshape(trainLabels[:,0].shape[0]),\n",
    "    \"lat_predicted\": predictions[:,1].reshape(predictions[:,1].shape[0]),\n",
    "    \"lat_actual\": trainLabels[:,1].reshape(trainLabels[:,1].shape[0])\n",
    "})\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_predicted, name=\"long_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_actual, name=\"long_actual\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_predicted, name=\"lat_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_actual, name=\"lat_actual\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac22938-94d9-4b9c-8ed0-8e6407dd2633",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74da5ebd-86c0-4d0f-a650-f3ba37fc639f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainingData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f008e1-2efd-44c8-b30f-dbed103bd599",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#specify input dimensionality\n",
    "numberOfSamples = trainingData.shape[0]\n",
    "inputDimension = trainingData[0].shape[0]*trainingData[0].shape[1]\n",
    "outputDimension = 1\n",
    "\n",
    "#construct our neural network\n",
    "hiddenLayerSizes = [inputDimension, 32, 16, 8, 4, 2]\n",
    "\n",
    "#set up our input layer\n",
    "inputLayer = layers.Input(shape=(inputDimension, 1))\n",
    "\n",
    "#set up our hidden layers\n",
    "curLayer = 0\n",
    "previousLayer = inputLayer\n",
    "for curLayerSize in hiddenLayerSizes:\n",
    "    previousLayer = layers.Conv1D(curLayerSize, 5,\n",
    "                                  activation='sigmoid',\n",
    "                                  name=str(curLayerSize)+'_hiddenLayer',\n",
    "                                  kernel_regularizer=regularizers.L2(0.001),\n",
    "                                  input_shape=(numberOfSamples, 5, 10)\n",
    "                                 )(previousLayer)\n",
    "    \n",
    "outputLayer = layers.Dense(outputDimension, activation='sigmoid')(previousLayer)\n",
    "\n",
    "#compile our model\n",
    "ourModel = Model(inputs=inputLayer, outputs=[outputLayer], name='longitude_cnn')\n",
    "ourModel.compile(loss='mean_squared_error', metrics=[tf.keras.metrics.RootMeanSquaredError()], optimizer='adam')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696074cb-d5a8-42b3-a46e-e95a096d9e3e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train the mlp\n",
    "trainingDataFlat = trainingData.reshape((-1, inputDimension))\n",
    "ourModel.fit(trainingDataFlat, longitudeLabels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a22f904-94a4-4fe4-80dc-a449e158153c",
   "metadata": {},
   "source": [
    "### CNN (new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec33b3-f4c6-4b51-a58a-f04eb51bbcbb",
   "metadata": {},
   "source": [
    "#### Split into training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e1d6181-1677-40be-bf36-03b787cb2407",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2b8a8d366c17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombinedLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongitudeLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatitudeLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrainInputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalInputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"samples\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombinedLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "combinedLabels = np.concatenate((np.reshape(longitudeLabels, (-1,1)), np.reshape(latitudeLabels, (-1,1))), axis=1)\n",
    "trainInputs, valInputs, trainLabels, valLabels = train_test_split(dataset[\"samples\"], combinedLabels, test_size=0.5, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb0eaf3-bc03-4919-ae92-a0180062d3dc",
   "metadata": {},
   "source": [
    "#### Construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe62585c-d137-4f66-98e8-64eadd1bca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify input dimensionality\n",
    "inputDimension = samples[0].shape[0]*samples[0].shape[1]\n",
    "outputDimension = 2\n",
    "\n",
    "#construct our neural network\n",
    "hiddenLayerSizes = [inputDimension, 32, 32, 32, 32]\n",
    "\n",
    "#set up our input layer\n",
    "inputLayer = layers.Input(shape=(sequenceLength, 13))\n",
    "\n",
    "#set up our hidden layers\n",
    "curLayer = 0\n",
    "previousLayer = inputLayer\n",
    "for i,curLayerSize in enumerate(hiddenLayerSizes):\n",
    "    previousLayer = layers.Conv1D(curLayerSize,\n",
    "                                  kernel_size=3,\n",
    "                                 activation='linear', \n",
    "                                 name=str(curLayerSize)+'_hiddenLayer'+str(i),\n",
    "                                  kernel_regularizer=regularizers.L2(0.001)\n",
    "                                )(previousLayer)\n",
    "    previousLayer = layers.LeakyReLU(alpha=0.3)(previousLayer)\n",
    "    previousLayer = layers.Dropout(\n",
    "                                    rate=0.5\n",
    "                                    )(previousLayer)\n",
    "previousLayer = layers.Flatten()(previousLayer)\n",
    "    \n",
    "outputLayer = layers.Dense(outputDimension, activation='sigmoid')(previousLayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcce964-77f4-4514-95af-57c2b9425d92",
   "metadata": {},
   "source": [
    "#### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c399c87-6fba-46db-bb98-1537fd33b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile separate models\n",
    "combinedModel = Model(inputs=inputLayer, outputs=[outputLayer], name='combined_mlp')\n",
    "combinedModel.compile(loss='mean_squared_error', metrics=[tf.keras.metrics.RootMeanSquaredError()], optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d8d86c-1b8a-446e-8bbc-c0765d8b136c",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11cdd89-7f44-47e2-893c-3d22cd1b9124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train the mlp\n",
    "combinedHistory = combinedModel.fit(trainInputs, trainLabels, epochs=5, batch_size=32, callbacks=[PlotLossesKeras()], validation_data=(valInputs, valLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfeccdf-f2b1-48fa-aa7c-95c1c69fc89d",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc9160-14c4-4eec-ae5a-e16a644a70d0",
   "metadata": {},
   "source": [
    "##### Predict Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d13d8d-c58c-45ca-9042-91ef38c14bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = combinedModel.predict(valInputs)\n",
    "\n",
    "scatterData = pd.DataFrame({\n",
    "    \"index\":np.arange(predictions[:,0].shape[0]),\n",
    "    \"long_predicted\": predictions[:,0].reshape(predictions[:,0].shape[0]),\n",
    "    \"long_actual\": valLabels[:,0].reshape(valLabels[:,0].shape[0]),\n",
    "    \"lat_predicted\": predictions[:,1].reshape(predictions[:,1].shape[0]),\n",
    "    \"lat_actual\": valLabels[:,1].reshape(valLabels[:,1].shape[0])\n",
    "})\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_predicted, name=\"long_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_actual, name=\"long_actual\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_predicted, name=\"lat_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_actual, name=\"lat_actual\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daadf233-16ac-4899-9ddb-47e884bb4a1a",
   "metadata": {},
   "source": [
    "##### Predict Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec6b0d-f1ba-4ae8-9b52-3b2150bd6594",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = combinedModel.predict(trainInputs)\n",
    "\n",
    "scatterData = pd.DataFrame({\n",
    "    \"index\":np.arange(predictions[:,0].shape[0]),\n",
    "    \"long_predicted\": predictions[:,0].reshape(predictions[:,0].shape[0]),\n",
    "    \"long_actual\": trainLabels[:,0].reshape(trainLabels[:,0].shape[0]),\n",
    "    \"lat_predicted\": predictions[:,1].reshape(predictions[:,1].shape[0]),\n",
    "    \"lat_actual\": trainLabels[:,1].reshape(trainLabels[:,1].shape[0])\n",
    "})\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_predicted, name=\"long_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_actual, name=\"long_actual\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_predicted, name=\"lat_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_actual, name=\"lat_actual\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea4c17c-e3c5-4a37-9550-6ebfeacb6216",
   "metadata": {},
   "source": [
    "### Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d21b30-51f6-4b0e-94c3-c5203be0dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdfdb47-1d3e-4bfa-9233-ad9bdb453dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences x samples x features\n",
    "\n",
    "#specify input dimensionality\n",
    "# numberOfSamples = trainingData.shape[0]\n",
    "inputDimension = 50\n",
    "outputDimension = 1\n",
    "\n",
    "#construct our neural network\n",
    "hiddenLayerSizes = [512]\n",
    "\n",
    "#set up our input layer\n",
    "\n",
    "#Will work for 2D convolution\n",
    "inputLayer = layers.Input(shape=(5, 10, 1))\n",
    "# inputLayer = layers.Input(shape=(5, 10))\n",
    "\n",
    "#set up our hidden layers\n",
    "curLayer = 0\n",
    "previousPreviousLayer = None\n",
    "previousLayer = inputLayer\n",
    "for i,curLayerSize in enumerate(hiddenLayerSizes):\n",
    "    previousPreviousLayer = previousLayer\n",
    "    previousLayer = layers.Conv2D(curLayerSize, (3,3),\n",
    "                                  activation='relu',\n",
    "                                  name='hiddenLayer_'+str(i),\n",
    "                                  kernel_regularizer=regularizers.L2(0.001),\n",
    "                                  padding=\"same\"\n",
    "                                 )(tf.keras.layers.Concatenate(axis=1)([previousPreviousLayer, previousLayer]))\n",
    "previousLayer = layers.Flatten()(previousLayer)\n",
    "outputLayer = layers.Dense(outputDimension, activation='linear')(previousLayer)\n",
    "\n",
    "#compile our model\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "longModel = Model(inputs=inputLayer, outputs=[outputLayer], name='longitude_resnet')\n",
    "latModel = Model(inputs=inputLayer, outputs=[outputLayer], name='latitude_resnet')\n",
    "longModel.compile(loss='mean_absolute_error', metrics=[tf.keras.metrics.RootMeanSquaredError()], optimizer=opt)\n",
    "latModel.compile(loss='mean_absolute_error', metrics=[tf.keras.metrics.RootMeanSquaredError()], optimizer=opt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16911014-527f-4b2a-bb2c-b3004f061678",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
    "print(\"Training longitude model:\")\n",
    "longModelHistory = longModel.fit(longTrainInputs, longTrainLabels, epochs=3, validation_data=(longValInputs, longValLabels))\n",
    "print(\"Training latitude model:\")\n",
    "latModelHistory = latModel.fit(latTrainInputs, latTrainLabels, epochs=3, validation_data=(latValInputs, latValLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b43619-e8b8-4d30-a9f3-a1389d45cbe5",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a7521-2516-49f6-8cb0-b5b56bd86379",
   "metadata": {},
   "outputs": [],
   "source": [
    "longPredictions = longModel.predict(longValInputs)\n",
    "latPredictions = latModel.predict(latValInputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe5ed1-51a2-477b-ade1-0f930cff0075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deltasToAbsolute(deltas, starting=0):\n",
    "    absolute = starting\n",
    "    for delta in deltas:\n",
    "        absolute+=delta\n",
    "    return absolute\n",
    "\n",
    "def deltasToAbsoluteSeries(deltas, starting=0):\n",
    "    absolute = starting\n",
    "    series = [starting]\n",
    "    for delta in deltas:\n",
    "        absolute+=delta\n",
    "        series.append(absolute)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413c73c-9ce1-47b6-b7be-7011ab2b0926",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterData = pd.DataFrame({\n",
    "    \"index\":np.arange(longPredictions.shape[0]),\n",
    "    \"long_predicted\": reverseNormalization(longPredictions.reshape(longPredictions.shape[0])),\n",
    "    \"long_actual\": reverseNormalization(longValLabels.reshape(longValLabels.shape[0])),\n",
    "    \"lat_predicted\": reverseNormalization(latPredictions.reshape(latPredictions.shape[0])),\n",
    "    \"lat_actual\": reverseNormalization(latValLabels.reshape(latValLabels.shape[0]))\n",
    "})\n",
    "scatterData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36521617-4bd8-4cfa-822f-105eca6ddbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_predicted, name=\"long_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_actual, name=\"long_actual\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_predicted, name=\"lat_predicted\"))\n",
    "fig.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_actual, name=\"lat_actual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff418bbe-1585-4dca-aca7-df4de3f63247",
   "metadata": {},
   "outputs": [],
   "source": [
    "latPredictions.all() == longPredictions.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e49d2c7-cf52-43f9-a224-d787cc973ebc",
   "metadata": {},
   "source": [
    "### Combined long-lat resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f493e6-e1b6-4ac8-b275-f4e18ea6ea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences x samples x features\n",
    "\n",
    "#specify input dimensionality\n",
    "# numberOfSamples = trainingData.shape[0]\n",
    "inputDimension = 50\n",
    "outputDimension = 2\n",
    "\n",
    "#construct our neural network\n",
    "hiddenLayerSizes = [50, 32, 32, 16, 16, 8]\n",
    "\n",
    "#set up our input layer\n",
    "\n",
    "#Will work for 2D convolution\n",
    "inputLayer = layers.Input(shape=(5, 10, 1))\n",
    "# inputLayer = layers.Input(shape=(5, 10))\n",
    "\n",
    "#set up our hidden layers\n",
    "curLayer = 0\n",
    "previousPreviousLayer = None\n",
    "previousLayer = inputLayer\n",
    "for i,curLayerSize in enumerate(hiddenLayerSizes):\n",
    "    previousPreviousLayer = previousLayer\n",
    "    previousLayer = layers.Conv2D(curLayerSize, (3,3),\n",
    "                                  activation='relu',\n",
    "                                  name='hiddenLayer_'+str(i),\n",
    "                                  kernel_regularizer=regularizers.L2(0.001),\n",
    "                                  padding=\"same\"\n",
    "                                 )(tf.keras.layers.Concatenate(axis=1)([previousPreviousLayer, previousLayer]))\n",
    "previousLayer = layers.Flatten()(previousLayer)\n",
    "outputLayer = layers.Dense(outputDimension, activation='linear')(previousLayer)\n",
    "\n",
    "#compile our model\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "combinedModel = Model(inputs=inputLayer, outputs=[outputLayer], name='combined_resnet')\n",
    "combinedModel.compile(loss='mean_squared_error', metrics=[tf.keras.metrics.RootMeanSquaredError()], optimizer=opt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab9d1e9-6870-4ead-8fc2-69976f2af4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "longTrainInputs, longValInputs, longTrainLabels, longValLabels = train_test_split(trainingData, longitudeLabels, test_size=0.5, shuffle=False)\n",
    "latTrainInputs, latValInputs, latTrainLabels, latValLabels = train_test_split(trainingData, latitudeLabels, test_size=0.5, shuffle=False)\n",
    "\n",
    "combinedTrainLabels = np.array(tuple(zip(longTrainLabels, latTrainLabels)))\n",
    "combinedValLabels = np.array(tuple(zip(longValLabels, latValLabels)))\n",
    "\n",
    "# tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
    "print(\"Training combined model:\")\n",
    "combinedModelHistory = combinedModel.fit(longTrainInputs, combinedTrainLabels, epochs=10, validation_data=(longValInputs, combinedValLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0958ea8-3ae7-42c1-acb4-8bd72c26a7c3",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523b8bc-c9bf-4626-a346-beeb07239fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedPredictions = combinedModel.predict(longValInputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365fd06e-cc7d-490e-ac21-1e9ca9ed3107",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd7b2c7-7566-4a1e-aabe-0ad81f389b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "longPredictions = combinedPredictions[:,0]\n",
    "latPredictions = combinedPredictions[:,1]\n",
    "\n",
    "longPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3509e8ef-4cf8-49e8-b02d-467eb64d105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "latPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2808340-46ed-48c3-a309-c4e65d8f5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterData = pd.DataFrame({\n",
    "    \"index\":np.arange(longPredictions.shape[0]),\n",
    "    \"long_predicted\": longPredictions,\n",
    "    \"long_actual\": longValLabels.reshape(longValLabels.shape[0]),\n",
    "    \"lat_predicted\": latPredictions,\n",
    "    \"lat_actual\": latValLabels.reshape(latValLabels.shape[0])\n",
    "})\n",
    "scatterData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b90ede9-d580-40d1-900b-3b9d863d0889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig1 = go.Figure()\n",
    "fig1.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_predicted, name=\"long_predicted\"))\n",
    "fig1.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_actual, name=\"long_actual\"))\n",
    "fig2 = go.Figure()\n",
    "fig2.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_predicted, name=\"lat_predicted\"))\n",
    "fig2.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_actual, name=\"lat_actual\"))\n",
    "\n",
    "fig1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877db482-33df-4a2f-806a-3ca0f05f9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d2b31-3f75-45a3-bd6f-d3ef14b96685",
   "metadata": {},
   "outputs": [],
   "source": [
    "latPredictions.all() == longPredictions.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3bc2dc-e9b4-4e66-ba7f-0ba9c31903de",
   "metadata": {},
   "outputs": [],
   "source": [
    "latValLabels.all() == longValLabels.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cddc44-de52-4dcf-8e92-ae56deb92693",
   "metadata": {},
   "source": [
    "### Combined Resnet with Absolute labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b7856-742d-409a-bd5a-b9241bec2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitudeLabels = []\n",
    "latitudeLabels = []\n",
    "\n",
    "for i,window in enumerate(stackedData[:-1]):\n",
    "    last = dataByLocation.iloc[i]\n",
    "    lastLong = last.Longitude\n",
    "    lastLat = last.Latitude\n",
    "    cur = dataByLocation.iloc[i+5]\n",
    "    curLong = cur.Longitude\n",
    "    curLat = cur.Latitude\n",
    "    \n",
    "    longitudeLabels.append(curLong)\n",
    "    latitudeLabels.append(curLat)\n",
    "\n",
    "longitudeLabels = np.array(longitudeLabels)\n",
    "latitudeLabels = np.array(latitudeLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e5d039-d409-4593-929c-c37582488217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=longitudeLabels, y=latitudeLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061fb9db-35a3-492b-98ce-4358c481ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences x samples x features\n",
    "\n",
    "#specify input dimensionality\n",
    "# numberOfSamples = trainingData.shape[0]\n",
    "inputDimension = 50\n",
    "outputDimension = 2\n",
    "\n",
    "#construct our neural network\n",
    "hiddenLayerSizes = [50, 32, 32, 16, 16, 8]\n",
    "\n",
    "#set up our input layer\n",
    "\n",
    "#Will work for 2D convolution\n",
    "inputLayer = layers.Input(shape=(5, 10, 1))\n",
    "# inputLayer = layers.Input(shape=(5, 10))\n",
    "\n",
    "#set up our hidden layers\n",
    "curLayer = 0\n",
    "previousPreviousLayer = None\n",
    "previousLayer = inputLayer\n",
    "for i,curLayerSize in enumerate(hiddenLayerSizes):\n",
    "    previousPreviousLayer = previousLayer\n",
    "    previousLayer = layers.Conv2D(curLayerSize, (3,3),\n",
    "#                                   activation='relu',\n",
    "                                  name='hiddenLayer_'+str(i),\n",
    "                                  kernel_regularizer=regularizers.L2(0.001),\n",
    "                                  padding=\"same\"\n",
    "                                 )(tf.keras.layers.Concatenate(axis=1)([previousPreviousLayer, previousLayer]))\n",
    "previousLayer = layers.Flatten()(previousLayer)\n",
    "outputLayer = layers.Dense(outputDimension, activation='linear')(previousLayer)\n",
    "\n",
    "#compile our model\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "combinedModel = Model(inputs=inputLayer, outputs=[outputLayer], name='absolute_combined_resnet')\n",
    "combinedModel.compile(loss='mean_squared_error', metrics=[tf.keras.metrics.RootMeanSquaredError()], optimizer=opt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239c5482-e2ca-4b54-a598-86085bbf0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "longTrainInputs, longValInputs, longTrainLabels, longValLabels = train_test_split(trainingData, longitudeLabels, test_size=0.5, shuffle=False)\n",
    "latTrainInputs, latValInputs, latTrainLabels, latValLabels = train_test_split(trainingData, latitudeLabels, test_size=0.5, shuffle=False)\n",
    "\n",
    "combinedTrainLabels = np.array(tuple(zip(longTrainLabels, latTrainLabels)))\n",
    "combinedValLabels = np.array(tuple(zip(longValLabels, latValLabels)))\n",
    "\n",
    "# tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
    "print(\"Training combined model:\")\n",
    "combinedModelHistory = combinedModel.fit(longTrainInputs, combinedTrainLabels, epochs=10, validation_data=(longValInputs, combinedValLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2f2eed-60d6-4d5d-91d8-50dfe136c6fd",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187ac24-0a0c-487e-be98-bd9dbe941d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedPredictions = combinedModel.predict(longValInputs)\n",
    "\n",
    "longPredictions = combinedPredictions[:,0]\n",
    "latPredictions = combinedPredictions[:,1]\n",
    "\n",
    "scatterData = pd.DataFrame({\n",
    "    \"index\":np.arange(longPredictions.shape[0]),\n",
    "    \"long_predicted\": longPredictions,\n",
    "    \"long_actual\": longValLabels.reshape(longValLabels.shape[0]),\n",
    "    \"lat_predicted\": latPredictions,\n",
    "    \"lat_actual\": latValLabels.reshape(latValLabels.shape[0])\n",
    "})\n",
    "scatterData.describe()\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig1 = go.Figure()\n",
    "fig1.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_predicted, name=\"long_predicted\"))\n",
    "fig1.add_trace(go.Scatter(x=scatterData.index, y=scatterData.long_actual, name=\"long_actual\"))\n",
    "fig2 = go.Figure()\n",
    "fig2.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_predicted, name=\"lat_predicted\"))\n",
    "fig2.add_trace(go.Scatter(x=scatterData.index, y=scatterData.lat_actual, name=\"lat_actual\"))\n",
    "\n",
    "fig1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2130b93a-6502-4088-a411-c0c6b7c717b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbafc18-ed1c-46c9-a7ba-a1e7835cda5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23e9488-7dac-430d-92df-e677b93e9a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
