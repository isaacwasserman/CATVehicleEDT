{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "79c843de-21e0-4dcc-aec2-fb8a133da849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets\n",
    "from sklearn import preprocessing\n",
    "import sklearn\n",
    "from datetime import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df8f01af-ce89-43ed-802d-40e6a9175949",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_weighted_average_interpolation = True\n",
    "nDrives = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc38425d-cbd7-43bf-bda8-83bbd712f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_weighted_average_interpolation:\n",
    "    drivePaths = [str(path) for path in Path(\".\").rglob(\"outputs/weightedInterpolation/dataByLocation*.csv\")][:nDrives]\n",
    "else:\n",
    "    drivePaths = [str(path) for path in Path(\".\").rglob(\"outputs/unweightedInterpolation/dataByLocation*.csv\")][:nDrives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7854164-6f51-47da-bcdd-00c03945aaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 drives that meet specifications\n"
     ]
    }
   ],
   "source": [
    "subsamplingPeriod = 1\n",
    "\n",
    "drivesWithLocation = []\n",
    "drivesWithoutLocation = []\n",
    "driveIDs = []\n",
    "for drivePath in drivePaths:\n",
    "    drive = pd.read_csv(drivePath)\n",
    "    if len(drive) > 1200:\n",
    "        driveIDs.append(\"_\".join(drivePath.split(\"/\")[-1].split(\"_\")[1:-1]))\n",
    "        drive = drive.iloc[::subsamplingPeriod]\n",
    "        driveWithoutLocation = drive.drop(columns=[\"Longitude\", \"Latitude\"])\n",
    "#         driveWithoutLocation = driveWithoutLocation.drop(columns=[\"ZAcceleration\", \"LongAcceleration\", \"LatAcceleration\"])\n",
    "        drivesWithLocation.append(drive)\n",
    "        drivesWithoutLocation.append(driveWithoutLocation)\n",
    "print(\"Found\", len(drivesWithoutLocation), \"drives that meet specifications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99176441-8661-4a80-a9d9-569c117d8040",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "18eb0077-dd66-4a6b-beb2-8848a6807855",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedDrives = []\n",
    "for drive in drivesWithoutLocation:\n",
    "    drive = drive.values[:]\n",
    "    standard_scaler = preprocessing.StandardScaler()\n",
    "    data_normalized = standard_scaler.fit_transform(drive)\n",
    "    data_normalized = pd.DataFrame(data_normalized)\n",
    "    data_normalized[0] = drive[:,0]\n",
    "    normalizedDrives.append(data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff082e-5f9a-43bd-994f-444c9c0f70af",
   "metadata": {},
   "source": [
    "## Smooth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5965449d-0682-42e5-85a8-970e4c845cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothDrives = []\n",
    "for drive in normalizedDrives:\n",
    "    smoothDriveSeries = []\n",
    "    for feature in drive.columns:\n",
    "        smoothDriveSeries.append(gaussian_filter(drive.iloc[:,feature], sigma=2))\n",
    "    smoothDrives.append(pd.DataFrame(smoothDriveSeries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e317d259-8054-4ea2-acaf-c9e1a07f2658",
   "metadata": {},
   "source": [
    "## Window Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a1d8b67e-4deb-41cc-b344-3b06556c0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenceLength = 10\n",
    "\n",
    "windowedDrives = []\n",
    "for drive in normalizedDrives:\n",
    "    data_df = drive\n",
    "    stackedData = []\n",
    "    # split can_data into subsampled sequences\n",
    "    for i in range(len(data_df)-sequenceLength):\n",
    "        stackedData.append(data_df[i:i+sequenceLength])\n",
    "    stackedData = np.array(stackedData)\n",
    "    windowedDrives.append(stackedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebacb18-c77b-42b7-b9f4-3433b4bd3339",
   "metadata": {},
   "source": [
    "## Add histogram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8f5d8fb5-a8f5-48b3-87fb-51779aba71aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "CANFiles = [str(PathObj) for PathObj in Path(\"./raw_data\").rglob(\"*_CAN_Messages.csv\")][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "86efe287-07a0-45aa-a303-494296625065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAssociatedCANFile(i):\n",
    "    driveID = driveIDs[i]\n",
    "    for path in CANFiles:\n",
    "        if driveID in path:\n",
    "            return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8cbdeba5-4697-4fd3-86a1-f40ca35ce22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = (1541,387,1552,1041,1553,1042,1556,1557,1044,544,1568,1056,1571,36,37,550,1059,552,1063,1570,1572,388,1941,562,1076,565,1077,1592,1082,1595,1084,1085,1086,1594,576,577,578,579,580,581,582,583,584,1088,1089,1948,1949,1104,1114,1952,608,610,1132,1649,1956,643,1161,1162,1163,1164,1165,1166,1167,658,1172,1696,1940,170,180,186,705,1973,1228,1745,1235,1237,728,740,742,743,1775,1264,1779,761,1786,1787,764,765,1788,1279,1789,1808,1809,1816,1817,800,291,296,810,812,814,304,1841,818,1840,1846,824,1848,829,830,835,836,352,865,353,869,870,871,877,1904,881,882,885,1912,889,896,384,898,385,900,386,902,391,392,905,393,394,395,396,397,398,399,401,400,402,403,404,918,405,406,921,407,408,409,410,411,412,413,414,415,416,417,933,934,935,418,419,426,389,390,1960,1964,944,945,436,437,438,951,439,440,441,955,956,442,443,1981,1986,452,1990,1994,1998,464,976,466,467,977,978,979,2004,2000,2008,987,2012,998,999,1000,1001,1002,1014,1017,1020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "883664a2-6036-4337-8c58-26130a30e8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "211\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n"
     ]
    }
   ],
   "source": [
    "debugNum = 10\n",
    "for i,drive in enumerate(windowedDrives):\n",
    "    associatedCANPath = getAssociatedCANFile(i)\n",
    "    associatedCAN = pd.read_csv(associatedCANPath)\n",
    "    datetimes = pd.to_datetime(associatedCAN.Time * (10**9))\n",
    "    associatedCAN = associatedCAN.set_index(datetimes)\n",
    "    for window in drive[:debugNum]:\n",
    "        windowStartTime = pd.to_datetime(window[0][0] * (10**9))\n",
    "        windowEndTime = pd.to_datetime(window[-1][0] * (10**9))\n",
    "        counts = dict(Counter(associatedCAN.loc[windowStartTime:windowEndTime].MessageID))\n",
    "        countList = []\n",
    "        for id in ids:\n",
    "            if id in counts:\n",
    "                countList.append(counts[id])\n",
    "            else:\n",
    "                countList.append(0)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502bdd98-d432-486c-8697-c70def7a9905",
   "metadata": {},
   "source": [
    "## Generate Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ed6e401-e123-4eec-a485-e58dbccb051c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = {\"samples\":[], \"labels\":[]}\n",
    "for k,drive in enumerate(windowedDrives):\n",
    "    for i,window in enumerate(drive[:-1]):\n",
    "        last = drivesWithLocation[k].iloc[i]\n",
    "        lastLong = last.Longitude\n",
    "        lastLat = last.Latitude\n",
    "        cur = drivesWithLocation[k].iloc[i+5]\n",
    "        curLong = cur.Longitude\n",
    "        curLat = cur.Latitude\n",
    "        \n",
    "        dataset[\"samples\"].append(window)\n",
    "        dataset[\"labels\"].append([curLong - lastLong, curLat - lastLat])\n",
    "# dataset = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5950f51-742c-4a0b-98e3-2d545de3b22d",
   "metadata": {},
   "source": [
    "### Normalize labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbb63034-81fd-41cf-85bb-e223ab52e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "originalLabels = dataset[\"labels\"]\n",
    "# originalLabels = np.array(originalLabels)\n",
    "\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# labels_normalized = scaler.fit_transform(originalLabels)\n",
    "# type(labels_normalized)\n",
    "labels_normalized = np.array(originalLabels) * (10**5)\n",
    "# print(labels_normalized.shape)\n",
    "# print(type(labels_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b616c171-5d5c-4a10-9de6-5758bf173461",
   "metadata": {},
   "source": [
    "## Smooth Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6318a934-4dbe-481e-bc33-818e1493fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 8\n",
    "smoothedLongitudeLabels = gaussian_filter(labels_normalized[:,0], sigma=sigma)\n",
    "smoothedLatitudeLabels = gaussian_filter(labels_normalized[:,1], sigma=sigma)\n",
    "\n",
    "smoothedLabels = np.vstack((smoothedLongitudeLabels, smoothedLatitudeLabels)).T\n",
    "\n",
    "# scatterData = pd.DataFrame({\n",
    "# \"index\":range(len(smoothedLongitudeLabels)),\n",
    "# \"smoothLongLabels\": smoothedLongitudeLabels,\n",
    "# \"originalLongLabels\": labels_normalized[:,0],\n",
    "# \"smoothLatLabels\": smoothedLatitudeLabels,\n",
    "# \"originalLatLabels\": labels_normalized[:,1],\n",
    "# })\n",
    "# scatterData.describe()\n",
    "\n",
    "# fig1 = go.Figure()\n",
    "# fig1.add_trace(go.Scatter(x=scatterData.index, y=scatterData.smoothLongLabels, name=\"gaussian smoothed long\"))\n",
    "# fig1.add_trace(go.Scatter(x=scatterData.index, y=scatterData.originalLongLabels, name=\"original long\"))\n",
    "# fig1.add_trace(go.Scatter(x=scatterData.index, y=scatterData.smoothLatLabels, name=\"gaussian smoothed lat\"))\n",
    "# fig1.add_trace(go.Scatter(x=scatterData.index, y=scatterData.originalLatLabels, name=\"original lat\"))\n",
    "\n",
    "# fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3672ed0-afcb-4d34-85eb-c79004e6774c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples = np.stack(dataset[\"samples\"])\n",
    "labels = smoothedLabels\n",
    "dataset = {\"samples\": samples, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36c0c3c-5232-408a-b708-9dc50b4a78bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1d0a529-e80e-477b-935f-7718f1cf735c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Its important to use binary mode\n",
    "dbfile = open('otherLargeFiles/CNN-dataset.pkl', 'ab')\n",
    "\n",
    "# source, destination\n",
    "pickle.dump(dataset, dbfile)                     \n",
    "dbfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5d23d0-5be9-43ca-9980-7e2483e0235e",
   "metadata": {},
   "source": [
    "## Other"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
