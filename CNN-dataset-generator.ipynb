{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79c843de-21e0-4dcc-aec2-fb8a133da849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets\n",
    "from sklearn import preprocessing\n",
    "import sklearn\n",
    "from datetime import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "df8f01af-ce89-43ed-802d-40e6a9175949",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_weighted_average_interpolation = True\n",
    "nDrives = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dc38425d-cbd7-43bf-bda8-83bbd712f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_weighted_average_interpolation:\n",
    "    drivePaths = [str(path) for path in Path(\".\").rglob(\"outputs/weightedInterpolation/dataByLocation*.csv\")][:nDrives]\n",
    "else:\n",
    "    drivePaths = [str(path) for path in Path(\".\").rglob(\"outputs/unweightedInterpolation/dataByLocation*.csv\")][:nDrives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e7854164-6f51-47da-bcdd-00c03945aaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41 drives that meet specifications\n"
     ]
    }
   ],
   "source": [
    "subsamplingPeriod = 1\n",
    "\n",
    "drivesWithLocation = []\n",
    "drivesWithoutLocation = []\n",
    "for drivePath in drivePaths:\n",
    "    drive = pd.read_csv(drivePath)\n",
    "    if len(drive) > 1200:\n",
    "        drive = drive.iloc[::subsamplingPeriod]\n",
    "        driveWithoutLocation = drive.drop(columns=[\"Time\", \"Longitude\", \"Latitude\"])\n",
    "#         driveWithoutLocation = driveWithoutLocation.drop(columns=[\"ZAcceleration\", \"LongAcceleration\", \"LatAcceleration\"])\n",
    "        drivesWithLocation.append(drive)\n",
    "        drivesWithoutLocation.append(driveWithoutLocation)\n",
    "print(\"Found\", len(drivesWithoutLocation), \"drives that meet specifications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99176441-8661-4a80-a9d9-569c117d8040",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "18eb0077-dd66-4a6b-beb2-8848a6807855",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedDrives = []\n",
    "for drive in drivesWithoutLocation:\n",
    "    drive = drive.values[:]\n",
    "    standard_scaler = preprocessing.StandardScaler()\n",
    "    data_normalized = standard_scaler.fit_transform(drive)\n",
    "    data_normalized = pd.DataFrame(data_normalized)\n",
    "    normalizedDrives.append(data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff082e-5f9a-43bd-994f-444c9c0f70af",
   "metadata": {},
   "source": [
    "## Smooth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5965449d-0682-42e5-85a8-970e4c845cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothDrives = []\n",
    "for drive in normalizedDrives:\n",
    "    smoothDriveSeries = []\n",
    "    for feature in drive.columns:\n",
    "        smoothDriveSeries.append(gaussian_filter(drive.iloc[:,feature], sigma=2))\n",
    "        #plot the original feature and the smoothed feature\n",
    "#         scatterData = pd.DataFrame({\n",
    "#         \"index\":range(drive.shape[0]),\n",
    "#         \"smoothData\": gaussian_filter(drive.iloc[:,feature], sigma=2),\n",
    "#         \"originalData\": drive.iloc[:,feature],\n",
    "#         })\n",
    "#         scatterData.describe()\n",
    "\n",
    "#         fig1 = go.Figure()\n",
    "#         fig1.add_trace(go.Scatter(x=scatterData.index, y=scatterData.smoothData, name=\"gaussian smoothed data\"))\n",
    "#         fig1.add_trace(go.Scatter(x=scatterData.index, y=scatterData.originalData, name=\"original data\"))\n",
    "\n",
    "#         fig1.show()\n",
    "    smoothDrives.append(pd.DataFrame(smoothDriveSeries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e317d259-8054-4ea2-acaf-c9e1a07f2658",
   "metadata": {},
   "source": [
    "## Window Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a1d8b67e-4deb-41cc-b344-3b06556c0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenceLength = 10\n",
    "features = ['Speed',\n",
    "            'LatAcceleration',\n",
    "            'LongAcceleration',\n",
    "            'SteerTorque',\n",
    "            'SteerRate',\n",
    "            'SteerAngle',\n",
    "            'FLWheelSpeed',\n",
    "            'FRWheelSpeed',\n",
    "            'RRWheelSpeed',\n",
    "            'RLWheelSpeed']\n",
    "\n",
    "windowedDrives = []\n",
    "for drive in normalizedDrives:\n",
    "    data_df = drive\n",
    "    stackedData = []\n",
    "    # split can_data into subsampled sequences\n",
    "    for i in range(len(data_df)-sequenceLength):\n",
    "        stackedData.append(data_df[i:i+sequenceLength])\n",
    "    stackedData = np.array(stackedData)\n",
    "    windowedDrives.append(stackedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502bdd98-d432-486c-8697-c70def7a9905",
   "metadata": {},
   "source": [
    "## Generate Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6ed6e401-e123-4eec-a485-e58dbccb051c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = {\"samples\":[], \"labels\":[]}\n",
    "for k,drive in enumerate(windowedDrives):\n",
    "    for i,window in enumerate(drive[:-1]):\n",
    "        last = drivesWithLocation[k].iloc[i]\n",
    "        lastLong = last.Longitude\n",
    "        lastLat = last.Latitude\n",
    "        cur = drivesWithLocation[k].iloc[i+5]\n",
    "        curLong = cur.Longitude\n",
    "        curLat = cur.Latitude\n",
    "        \n",
    "        dataset[\"samples\"].append(window)\n",
    "        dataset[\"labels\"].append([curLong - lastLong, curLat - lastLat])\n",
    "# dataset = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5950f51-742c-4a0b-98e3-2d545de3b22d",
   "metadata": {},
   "source": [
    "### Normalize labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bbb63034-81fd-41cf-85bb-e223ab52e6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(556450, 2)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "originalLabels = dataset[\"labels\"]\n",
    "# originalLabels = np.array(originalLabels)\n",
    "\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# labels_normalized = scaler.fit_transform(originalLabels)\n",
    "# type(labels_normalized)\n",
    "labels_normalized = np.array(originalLabels) * (10**5)\n",
    "print(labels_normalized.shape)\n",
    "print(type(labels_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b616c171-5d5c-4a10-9de6-5758bf173461",
   "metadata": {},
   "source": [
    "## Smooth Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6318a934-4dbe-481e-bc33-818e1493fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 8\n",
    "smoothedLongitudeLabels = gaussian_filter(labels_normalized[:,0], sigma=sigma)\n",
    "smoothedLatitudeLabels = gaussian_filter(labels_normalized[:,1], sigma=sigma)\n",
    "\n",
    "smoothedLabels = np.vstack((smoothedLongitudeLabels, smoothedLatitudeLabels)).T\n",
    "\n",
    "# scatterData = pd.DataFrame({\n",
    "# \"index\":range(len(smoothedLongitudeLabels)),\n",
    "# \"smoothLongLabels\": smoothedLongitudeLabels,\n",
    "# \"originalLongLabels\": labels_normalized[:,0],\n",
    "# \"smoothLatLabels\": smoothedLatitudeLabels,\n",
    "# \"originalLatLabels\": labels_normalized[:,1],\n",
    "# })\n",
    "# scatterData.describe()\n",
    "\n",
    "# fig1 = go.Figure()\n",
    "# fig1.add_trace(go.Scatter(x=scatterData.index, y=scatterData.smoothLongLabels, name=\"gaussian smoothed long\"))\n",
    "# fig1.add_trace(go.Scatter(x=scatterData.index, y=scatterData.originalLongLabels, name=\"original long\"))\n",
    "# fig1.add_trace(go.Scatter(x=scatterData.index, y=scatterData.smoothLatLabels, name=\"gaussian smoothed lat\"))\n",
    "# fig1.add_trace(go.Scatter(x=scatterData.index, y=scatterData.originalLatLabels, name=\"original lat\"))\n",
    "\n",
    "# fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f3672ed0-afcb-4d34-85eb-c79004e6774c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples = np.stack(dataset[\"samples\"])\n",
    "labels = smoothedLabels\n",
    "dataset = {\"samples\": samples, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36c0c3c-5232-408a-b708-9dc50b4a78bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f1d0a529-e80e-477b-935f-7718f1cf735c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Its important to use binary mode\n",
    "dbfile = open('otherLargeFiles/CNN-dataset.pkl', 'ab')\n",
    "\n",
    "# source, destination\n",
    "pickle.dump(dataset, dbfile)                     \n",
    "dbfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
