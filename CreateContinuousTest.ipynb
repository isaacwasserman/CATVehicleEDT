{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c0647e7-f352-492d-835b-8fce71921c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets\n",
    "from sklearn import preprocessing\n",
    "import sklearn\n",
    "from datetime import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79fac01a-8cc6-4052-a7c8-1873c8cf65c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nDrives = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "779ddea8-b7cb-4a93-90a8-97e0349c0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivePaths = [str(path) for path in Path(\".\").rglob(\"outputs/withNewFeatures/dataByLocation*.csv\")][:nDrives]\n",
    "drivePaths = [\"./outputs/withNewFeatures/dataByLocation_2021-06-08-15-01-31_2T3Y1RFV8KC014025.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81575c5a-3130-4928-9bb4-b77bc42a91e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 drives that meet specifications\n"
     ]
    }
   ],
   "source": [
    "subsamplingPeriod = 1\n",
    "\n",
    "drivesWithLocation = []\n",
    "drivesWithoutLocation = []\n",
    "driveIDs = []\n",
    "for drivePath in drivePaths:\n",
    "    drive = pd.read_csv(drivePath)\n",
    "    if len(drive) > 1200 and \"dataByLocation_2021-06-03-19-38-35_2T3Y1RFV8KC014025.csv\" not in drivePath:\n",
    "        driveIDs.append(\"_\".join(drivePath.split(\"/\")[-1].split(\"_\")[1:-1]))\n",
    "        drive = drive.iloc[::subsamplingPeriod]\n",
    "        driveWithoutLocation = drive.drop(columns=[\"Time\",\"Longitude\", \"Latitude\"])\n",
    "#         driveWithoutLocation = driveWithoutLocation.drop(columns=[\"ZAcceleration\", \"LongAcceleration\", \"LatAcceleration\"])\n",
    "        drivesWithLocation.append(drive)\n",
    "        drivesWithoutLocation.append(driveWithoutLocation)\n",
    "print(\"Found\", len(drivesWithoutLocation), \"drives that meet specifications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d650130-45fa-4016-915b-38a5a93df700",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9769f4d6-3443-4ffd-ba5f-a6f72af1cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerFile = open('otherLargeFiles/scalerUsedForTrainingInputs.pkl', 'rb')\n",
    "scaler = pickle.load(scalerFile)                     \n",
    "scalerFile.close()\n",
    "\n",
    "normalizedDrives = []\n",
    "for drive in drivesWithoutLocation:\n",
    "    drive = drive.values[:]\n",
    "    data_normalized = scaler.transform(drive)\n",
    "    data_normalized = pd.DataFrame(data_normalized)\n",
    "    data_normalized[0] = drive[:,0]\n",
    "    normalizedDrives.append(data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a1847f-bc0f-4ef9-9d33-63dc759ad71f",
   "metadata": {},
   "source": [
    "## Window (discrete) and Generate Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09088cd4-cece-4363-a3cf-c2695bc1b15a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on drive 0  Has 1800 windows worth of samples\n"
     ]
    }
   ],
   "source": [
    "# Faster\n",
    "sequenceLength = 10\n",
    "\n",
    "windowsPerDrive = []\n",
    "for drive in normalizedDrives:\n",
    "    nWindows = math.floor(len(drive) / sequenceLength)\n",
    "    if len(drive) % sequenceLength == 0:\n",
    "        nWindows-=1\n",
    "    windowsPerDrive.append(nWindows)\n",
    "    \n",
    "datasetLength = sum(windowsPerDrive)\n",
    "dataset = {\"samples\":np.full((datasetLength, sequenceLength, len(normalizedDrives[0].columns)), -1.),\"labels\":np.full((datasetLength, 2), -1.)}\n",
    "datasetIndex = 0\n",
    "\n",
    "for k,drive in enumerate(normalizedDrives):\n",
    "    nWindows = windowsPerDrive[k]\n",
    "    print(\"on drive\",k, \" Has\", nWindows, \"windows worth of samples\")\n",
    "    for i in range(nWindows):\n",
    "        windowStartIndex = i * sequenceLength\n",
    "        windowEndIndex = windowStartIndex + sequenceLength\n",
    "        window = drive.iloc[windowStartIndex:windowEndIndex].to_numpy()\n",
    "        startWithLocation = drivesWithLocation[k].iloc[windowStartIndex]\n",
    "        startLong = startWithLocation.Longitude\n",
    "        startLat = startWithLocation.Latitude\n",
    "        nextWithLocation = drivesWithLocation[k].iloc[windowEndIndex]\n",
    "        nextLong = nextWithLocation.Longitude\n",
    "        nextLat = nextWithLocation.Latitude\n",
    "        deltaLong = nextLong - startLong\n",
    "        deltaLat = nextLat - startLat\n",
    "        deltas = [deltaLong, deltaLat]\n",
    "        dataset[\"samples\"][datasetIndex] = window\n",
    "        dataset[\"labels\"][datasetIndex] = deltas\n",
    "        datasetIndex+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5253e5e4-a20e-4634-bc65-779fde42bed2",
   "metadata": {},
   "source": [
    "### Normalize labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffecab3c-4706-46b2-a9d8-5556bd226aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerFile = open('otherLargeFiles/scalerUsedForTrainingLabels.pkl', 'rb')\n",
    "scaler = pickle.load(scalerFile)                     \n",
    "scalerFile.close()\n",
    "\n",
    "originalLabels = dataset[\"labels\"]\n",
    "labels_normalized = scaler.transform(originalLabels)\n",
    "dataset[\"labels\"] = labels_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d5a041-74af-4253-8542-d80b81637edf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f91e90e-35b4-42aa-a2ba-11df51b7a932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nextTestNumber = max([int(str(path).split(\".\")[0].split(\"-\")[-1]) for path in Path(\"./otherLargeFiles\").rglob(\"test-drive*\")], default=-1) + 1\n",
    "dbfile = open(f'otherLargeFiles/test-drive-{str(nextTestNumber)}.pkl', 'ab')\n",
    "\n",
    "# source, destination\n",
    "pickle.dump(dataset, dbfile)                     \n",
    "dbfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ce9c0-326c-4ec5-801e-bc15233e4c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
