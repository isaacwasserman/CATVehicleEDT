{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c843de-21e0-4dcc-aec2-fb8a133da849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets\n",
    "from sklearn import preprocessing\n",
    "import sklearn\n",
    "from datetime import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df8f01af-ce89-43ed-802d-40e6a9175949",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_weighted_average_interpolation = True\n",
    "use_new_features = True\n",
    "nDrives = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc38425d-cbd7-43bf-bda8-83bbd712f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_weighted_average_interpolation:\n",
    "    drivePaths = [str(path) for path in Path(\".\").rglob(\"outputs/weightedInterpolation/dataByLocation*.csv\")][:nDrives]\n",
    "else:\n",
    "    drivePaths = [str(path) for path in Path(\".\").rglob(\"outputs/unweightedInterpolation/dataByLocation*.csv\")][:nDrives]\n",
    "    \n",
    "if use_new_features:\n",
    "    drivePaths = [str(path) for path in Path(\".\").rglob(\"outputs/withNewFeatures/dataByLocation*.csv\")][:nDrives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7854164-6f51-47da-bcdd-00c03945aaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 drives that meet specifications\n"
     ]
    }
   ],
   "source": [
    "subsamplingPeriod = 1\n",
    "\n",
    "drivesWithLocation = []\n",
    "drivesWithoutLocation = []\n",
    "driveIDs = []\n",
    "for drivePath in drivePaths:\n",
    "    drive = pd.read_csv(drivePath)\n",
    "    if len(drive) > 1200 and \"dataByLocation_2021-06-03-19-38-35_2T3Y1RFV8KC014025.csv\" not in drivePath:\n",
    "        driveIDs.append(\"_\".join(drivePath.split(\"/\")[-1].split(\"_\")[1:-1]))\n",
    "        drive = drive.iloc[::subsamplingPeriod]\n",
    "        driveWithoutLocation = drive.drop(columns=[\"Time\",\"Longitude\", \"Latitude\"])\n",
    "#         driveWithoutLocation = driveWithoutLocation.drop(columns=[\"ZAcceleration\", \"LongAcceleration\", \"LatAcceleration\"])\n",
    "        drivesWithLocation.append(drive)\n",
    "        drivesWithoutLocation.append(driveWithoutLocation)\n",
    "print(\"Found\", len(drivesWithoutLocation), \"drives that meet specifications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99176441-8661-4a80-a9d9-569c117d8040",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18eb0077-dd66-4a6b-beb2-8848a6807855",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedDrives = []\n",
    "combinedDrivesForScalerFitting = pd.concat(drivesWithoutLocation).reset_index().drop(columns=[\"index\"])\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "standard_scaler.fit(combinedDrivesForScalerFitting)\n",
    "\n",
    "for drive in drivesWithoutLocation:\n",
    "    drive = drive.values[:]\n",
    "    data_normalized = standard_scaler.transform(drive)\n",
    "    data_normalized = pd.DataFrame(data_normalized)\n",
    "    data_normalized[0] = drive[:,0]\n",
    "    normalizedDrives.append(data_normalized)\n",
    "    \n",
    "scalerFile = open('otherLargeFiles/scalerUsedForTrainingInputs.pkl', 'ab')\n",
    "pickle.dump(standard_scaler, scalerFile)                     \n",
    "scalerFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502bdd98-d432-486c-8697-c70def7a9905",
   "metadata": {},
   "source": [
    "## Generate Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b34b0ad0-95cd-40a0-8204-2b4913f95f23",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on drive 0\n",
      "on drive 1\n",
      "on drive 2\n",
      "on drive 3\n",
      "on drive 4\n",
      "on drive 5\n",
      "on drive 6\n",
      "on drive 7\n",
      "on drive 8\n",
      "on drive 9\n",
      "on drive 10\n",
      "on drive 11\n",
      "on drive 12\n",
      "on drive 13\n",
      "on drive 14\n",
      "on drive 15\n",
      "on drive 16\n",
      "on drive 17\n",
      "on drive 18\n",
      "on drive 19\n",
      "on drive 20\n",
      "on drive 21\n",
      "on drive 22\n",
      "on drive 23\n",
      "on drive 24\n",
      "on drive 25\n",
      "on drive 26\n",
      "on drive 27\n",
      "on drive 28\n",
      "on drive 29\n",
      "on drive 30\n",
      "on drive 31\n",
      "on drive 32\n",
      "on drive 33\n",
      "on drive 34\n",
      "on drive 35\n",
      "on drive 36\n",
      "on drive 37\n",
      "on drive 38\n",
      "on drive 39\n"
     ]
    }
   ],
   "source": [
    "# Faster\n",
    "sequenceLength = 10\n",
    "datasetLength = sum([len(drive) for drive in normalizedDrives]) - ((sequenceLength + 1)*len(normalizedDrives))\n",
    "dataset = {\"samples\":np.full((datasetLength, sequenceLength, len(normalizedDrives[0].columns)), -1.),\"labels\":np.full((datasetLength, 2), -1.)}\n",
    "datasetIndex = 0\n",
    "\n",
    "for k,drive in enumerate(normalizedDrives):\n",
    "    print(\"on drive\",k)\n",
    "    for i,sample in drive.iterrows():\n",
    "        if i < len(drive) - sequenceLength - 1:\n",
    "            thisDriveWithLocation = drivesWithLocation[k]\n",
    "            thisSampleWithLocation = thisDriveWithLocation.iloc[i]\n",
    "            thisLong = thisSampleWithLocation.Longitude\n",
    "            thisLat = thisSampleWithLocation.Latitude\n",
    "            nextSample = thisDriveWithLocation.iloc[i+sequenceLength]\n",
    "            nextLong = nextSample.Longitude\n",
    "            nextLat = nextSample.Latitude\n",
    "            deltaLong = nextLong - thisLong\n",
    "            deltaLat = nextLat - thisLat\n",
    "            deltas = [deltaLong, deltaLat]\n",
    "            dataset[\"samples\"][datasetIndex] = [drive.iloc[i+n].to_numpy() for n in range(sequenceLength)]\n",
    "            dataset[\"labels\"][datasetIndex] = deltas\n",
    "            datasetIndex+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5950f51-742c-4a0b-98e3-2d545de3b22d",
   "metadata": {},
   "source": [
    "### Normalize labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb63034-81fd-41cf-85bb-e223ab52e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "originalLabels = dataset[\"labels\"]\n",
    "# originalLabels = np.array(originalLabels)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "labels_normalized = scaler.fit_transform(originalLabels)\n",
    "dataset[\"labels\"] = labels_normalized\n",
    "\n",
    "scalerFile = open('otherLargeFiles/scalerUsedForTrainingLabels.pkl', 'ab')\n",
    "pickle.dump(scaler, scalerFile)                     \n",
    "scalerFile.close()\n",
    "\n",
    "# type(labels_normalized)\n",
    "# labels_normalized = originalLabels\n",
    "# print(labels_normalized.shape)\n",
    "# print(type(labels_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36c0c3c-5232-408a-b708-9dc50b4a78bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1d0a529-e80e-477b-935f-7718f1cf735c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Its important to use binary mode\n",
    "dbfile = open('otherLargeFiles/CNN-dataset.pkl', 'ab')\n",
    "\n",
    "# source, destination\n",
    "pickle.dump(dataset, dbfile)                     \n",
    "dbfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c519ac9-fbf3-4add-b9e8-299bc9064bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
